# -*- coding: utf-8 -*-
"""
Created on Tue Jul  7 12:39:17 2020

@author: David
"""
import scapy.all
import sys
from functools import reduce
import operator
from collections import defaultdict
from ...utils.dictionary import prefix_dict_keys
from .bases import (
        BaseFlowProcessor, payload_size, BaseProcessor
)
from .statistics import SummaryStatistics
from .packet import ByteStatistics


def closing_TCP(packet):
    '''
    Determines whether a packet closes a TCP connection or not.

    It is considered that a packet closes a TCP connection when is a TCP
    packet and has a FIN or RST flag active.
    '''
    return (scapy.all.TCP in packet and
            (packet['TCP'].flags.F or packet['TCP'].flags.R))


class Flow:
    '''
    Base class to model a sequence of packets
    '''
    def __init__(self):
        self.packets = []

    def add(self, packet):
        self.packets.append(packet)

    def __iter__(self):
        return (packet for packet in self.packets)

    def packet_timestamp(self, index):
        try:
            return float(self.packets[index].time)
        except IndexError:
            return sys.float_info.max

    def last_packet_timestamp(self):
        return self.packet_timestamp(-1)

    def first_packet_timestamp(self):
        return self.packet_timestamp(0)

    def duration(self):
        return self.last_packet_timestamp() - self.first_packet_timestamp()

    def __bool__(self):
        return len(self.packets) > 0


class HTTPFlowByteStatistics(ByteStatistics, BaseFlowProcessor):
    '''
    Compute statistics related to HTTP traffic byte flows
    '''
    def compute_quantity(self, packet):
        return payload_size(packet)

    def valid(self, flow):
        return reduce(
                operator.__or__,
                map(lambda x: scapy.layers.http.HTTP in x, flow)
        )

    def _process(self, flow):
        for packet in flow:
            ByteStatistics._process(self, packet)

    def return_metrics(self):
        metrics = ByteStatistics.return_metrics(self)
        prefix_dict_keys(metrics, 'HTTP_')
        return metrics


class FlowGenerator(BaseProcessor):
    '''
    Base class that process packets and reconstruct the flows found in traffic.

    A flow is defined as a set of ordered bidirectional packets interchanged
    defined by a tuple:
        (IP source, IP destination, port source, port destination, protocol)

    A flow is finished when is explicitly closed (TCP supports this) or when
    the time between two packets of the flow is greater than a timeout.
    '''
    timeout = 7.5

    def __init__(self):
        # Flows are stored in a dict whose keys are the tuple defined above
        self.active_flows = defaultdict(Flow)
        self.completed_flows = []

    def is_timeout(self, flow, packet):
        return float(packet.time) - flow.last_packet_timestamp() > self.timeout

    def finish_flow(self, key):
        # self.completed_flows.append(self.active_flows[key])
        return self.active_flows.pop(key)
        # return self.completed_flows[-1]

    def check_timeout(self, packet):
        for key in tuple(self.active_flows):
            if self.is_timeout(self.active_flows[key], packet):
                self.finish_flow(key)

    def finish_all(self):
        for key in list(self.active_flows):
            self.finish_flow(key)

    def _process(self, packet):
        key = packet.construct_key()
        flow = self.active_flows[key]
        # Packet closes TCP connection
        if closing_TCP(packet):
            flow.add(packet)
            self.finish_flow(key)
        else:
            self.check_timeout(packet)
            self.active_flows[key].add(packet)


class FlowProcessor(FlowGenerator):
    '''
    Class that aglutinates flow processors and combines their results.

    Instance Attributes
    ---------------------------
    processors: tuple<BaseFlowProcessor>
        The processors to be executed
    '''
    def __init__(self, *args):
        FlowGenerator.__init__(self)
        self.processors = args

    def finish_flow(self, key):
        completed = FlowGenerator.finish_flow(self, key)
        for processor in self.processors:
            # processor.process(self.completed_flows[-1])
            processor.process(completed)
        del completed

    def return_metrics(self):
        self.finish_all()
        metrics = [processor.return_metrics() for processor in self.processors]
        total = {}
        for processor in self.processors:
            m = processor.return_metrics()
            metrics.append(m)
        for metric_dict in metrics:
            total.update(metric_dict)
        return total


class FlowByteStatistics(BaseFlowProcessor):
    '''
    Computes statistics related to byte flows per flow.
    '''
    def __init__(self):
        self.flow_statistics = []

    def _process(self, flow):
        bs = ByteStatistics()
        for packet in flow:
            bs.process(packet)
        self.flow_statistics.append(bs)

    def return_metrics(self):
        byte_counts = [bs.inbound_sum() + bs.outbound_sum()
                       for bs in self.flow_statistics]
        packet_counts = [bs.inbound_count() + bs.outbound_count()
                         for bs in self.flow_statistics]

        bs_bytes = SummaryStatistics()
        bs_bytes.add_multiple(byte_counts)
        bs_packets = SummaryStatistics()
        bs_packets.add_multiple(packet_counts)

        byte_metrics = bs_bytes.return_metrics()
        del byte_metrics['sum']
        prefix_dict_keys(byte_metrics, 'flow_byte_')

        packet_metrics = bs_packets.return_metrics()
        del packet_metrics['sum']
        del packet_metrics['count']
        prefix_dict_keys(packet_metrics, 'flow_packet_')

        byte_metrics.update(packet_metrics)
        return byte_metrics


class FlowDurationStatistics(BaseFlowProcessor):
    '''
    Computes statistics realted to the duration of the flows.
    '''
    def __init__(self):
        self.statistics = SummaryStatistics()

    def _process(self, flow):
        self.statistics.add(flow.duration())

    def return_metrics(self):
        metrics = self.statistics.return_metrics()
        del metrics['count']
        prefix_dict_keys(metrics, 'flow_duration_')

        return metrics


def flow_processor_list():
    '''
    Returns a list of all defined flow processors

    Returns
    -------------------------
    flow_processors: list<class>
        The list of defined flow processor classes
    '''
    return [FlowDurationStatistics, FlowByteStatistics, HTTPFlowByteStatistics]


def construct_flow_processors():
    '''
    Creates an instance of each class in flow_processor_list()

    Returns
    -----------------------
    flow_processors: list<BaseFlowProcessor>
        The list of instances
    '''
    return [cls() for cls in flow_processor_list()]
